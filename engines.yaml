# engines.yaml is a YAML file that contains the configuration for the AI engines and models.
# Note: The default max tokens is used when the max tokens is not specified in the request.
# Updated: October 2025 with latest models
# max_input_tokens: Maximum tokens for input (context window)
# max_output_tokens: Maximum tokens the model can generate in response
# default_max_tokens: Recommended default with safety margin (typically 80% of max_output_tokens)
engines:
  - name: openai
    api_key_name: OPENAI_API_KEY
    models:
      # GPT-4o - Latest multimodal model (most widely available)
      - name: gpt-4o
        supports_system_role: true
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 128000
        max_output_tokens: 16384
        default_max_tokens: 4096
      - name: gpt-4o-mini
        supports_system_role: true
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 128000
        max_output_tokens: 16384
        default_max_tokens: 4096
      # GPT-4 Turbo - Previous generation
      - name: gpt-4-turbo
        supports_system_role: true
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 128000
        max_output_tokens: 4096
        default_max_tokens: 4096
    default_model: gpt-4o
  - name: anthropic
    api_key_name: ANTHROPIC_API_KEY
    models:
      # Claude 4.5 Sonnet - Latest and most capable (Sep 2025)
      - name: claude-sonnet-4-5-20250929
        supports_system_role: true
        max_temperature: 1
        temperature: 0.75
        max_input_tokens: 200000
        max_output_tokens: 64000
        default_max_tokens: 8192
      # Claude 4 Opus 4.1 - World's best coding model (Aug 2025)
      - name: claude-opus-4-1-20250805
        supports_system_role: true
        max_temperature: 1
        temperature: 0.75
        max_input_tokens: 200000
        max_output_tokens: 64000
        default_max_tokens: 8192
      # Claude 4 Sonnet - Strong coding and reasoning (May 2025)
      - name: claude-sonnet-4-20250514
        supports_system_role: true
        max_temperature: 1
        temperature: 0.75
        max_input_tokens: 200000
        max_output_tokens: 64000
        default_max_tokens: 8192
      # Claude 4 Opus - Complex long-running tasks (May 2025)
      - name: claude-4-opus-20250514
        supports_system_role: true
        max_temperature: 1
        temperature: 0.75
        max_input_tokens: 200000
        max_output_tokens: 64000
        default_max_tokens: 8192
      # Claude 3.7 Sonnet - Hybrid reasoning model (Feb 2025)
      - name: claude-3-7-sonnet-20250219
        supports_system_role: true
        max_temperature: 1
        temperature: 0.75
        max_input_tokens: 200000
        max_output_tokens: 8192
        default_max_tokens: 8192
      # Claude 3.5 Sonnet - Previous generation flagship (Oct 2024)
      - name: claude-3-5-sonnet-20241022
        supports_system_role: true
        max_temperature: 1
        temperature: 0.75
        max_input_tokens: 200000
        max_output_tokens: 8192
        default_max_tokens: 8192
    default_model: claude-sonnet-4-5-20250929
  - name: google
    api_key_name: GOOGLE_API_KEY
    models:
      # Gemini 1.5 Pro - Most capable model (using direct API with gemini/ prefix)
      - name: gemini/gemini-1.5-pro
        supports_system_role: false
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 2097152
        max_output_tokens: 8192
        default_max_tokens: 8192
      # Gemini 1.5 Flash - Fast and efficient
      - name: gemini/gemini-1.5-flash
        supports_system_role: false
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 1048576
        max_output_tokens: 8192
        default_max_tokens: 8192
      # Specific versioned models
      - name: gemini/gemini-1.5-pro-002
        supports_system_role: false
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 2097152
        max_output_tokens: 8192
        default_max_tokens: 8192
      - name: gemini/gemini-1.5-flash-002
        supports_system_role: false
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 1048576
        max_output_tokens: 8192
        default_max_tokens: 8192
    default_model: gemini/gemini-1.5-pro

default: anthropic
# These are the preset creativity temperature settings for the engine and model.
temperature_settings:
  precise: 0.25
  balanced: 0.50
  creative: 0.75
