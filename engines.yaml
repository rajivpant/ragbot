# engines.yaml is a YAML file that contains the configuration for the AI engines and models.
# Note: The default max tokens is used when the max tokens is not specified in the request.
# Updated: October 2025 with latest models
# max_input_tokens: Maximum tokens for input (context window)
# max_output_tokens: Maximum tokens the model can generate in response
# default_max_tokens: Recommended default with safety margin (typically 80% of max_output_tokens)
engines:
  - name: openai
    api_key_name: OPENAI_API_KEY
    models:
      # o3 Series - Advanced reasoning models (2025)
      - name: o3
        category: reasoning
        supports_system_role: true
        max_temperature: 1
        temperature: 1
        max_input_tokens: 200000
        max_output_tokens: 100000
        default_max_tokens: 8192
      - name: o3-mini
        category: reasoning
        supports_system_role: true
        max_temperature: 1
        temperature: 1
        max_input_tokens: 200000
        max_output_tokens: 100000
        default_max_tokens: 8192
      # o4 Series - Reasoning with multimodal (2025)
      - name: o4-mini
        category: reasoning
        supports_system_role: true
        max_temperature: 1
        temperature: 1
        max_input_tokens: 200000
        max_output_tokens: 100000
        default_max_tokens: 8192
      # GPT-4.1 Series - Latest flagship models (2025)
      - name: gpt-4.1
        category: large
        supports_system_role: true
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 1000000
        max_output_tokens: 16384
        default_max_tokens: 8192
      - name: gpt-4.1-mini
        category: medium
        supports_system_role: true
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 1000000
        max_output_tokens: 16384
        default_max_tokens: 8192
      # GPT-4o - Multimodal flagship model
      - name: gpt-4o
        category: medium
        supports_system_role: true
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 128000
        max_output_tokens: 16384
        default_max_tokens: 4096
      # GPT-4o Mini - Fast and cost-effective
      - name: gpt-4o-mini
        category: small
        supports_system_role: true
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 128000
        max_output_tokens: 16384
        default_max_tokens: 4096
    default_model: gpt-4.1
  - name: anthropic
    api_key_name: ANTHROPIC_API_KEY
    models:
      # Claude Sonnet 4.5 - Latest and most capable (Sep 2025)
      - name: claude-sonnet-4-5-20250929
        category: medium
        supports_system_role: true
        max_temperature: 1
        temperature: 0.75
        max_input_tokens: 200000
        max_output_tokens: 64000
        default_max_tokens: 8192
      # Claude Opus 4.1 - Most powerful reasoning (Aug 2025)
      - name: claude-opus-4-1-20250805
        category: large
        supports_system_role: true
        max_temperature: 1
        temperature: 0.75
        max_input_tokens: 200000
        max_output_tokens: 64000
        default_max_tokens: 8192
      # Claude Haiku 4.5 - Fast and cost-effective (Oct 2025)
      - name: claude-haiku-4-5
        category: small
        supports_system_role: true
        max_temperature: 1
        temperature: 0.75
        max_input_tokens: 200000
        max_output_tokens: 64000
        default_max_tokens: 8192
      # Claude 3.5 Haiku - Previous generation (Oct 2024)
      - name: claude-3-5-haiku-20241022
        category: small
        supports_system_role: true
        max_temperature: 1
        temperature: 0.75
        max_input_tokens: 200000
        max_output_tokens: 8192
        default_max_tokens: 8192
    default_model: claude-sonnet-4-5-20250929
  - name: google
    api_key_name: GOOGLE_API_KEY
    models:
      # Gemini 2.5 Pro - Most capable reasoning model
      - name: gemini/gemini-2.5-pro
        category: large
        supports_system_role: false
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 1048576
        max_output_tokens: 65536
        default_max_tokens: 8192
      - name: gemini/gemini-pro-latest
        category: large
        supports_system_role: false
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 1048576
        max_output_tokens: 65536
        default_max_tokens: 8192
      # Gemini 2.5 Flash - Balanced speed and capability
      - name: gemini/gemini-2.5-flash
        category: medium
        supports_system_role: false
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 1048576
        max_output_tokens: 65536
        default_max_tokens: 8192
      - name: gemini/gemini-flash-latest
        category: medium
        supports_system_role: false
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 1048576
        max_output_tokens: 65536
        default_max_tokens: 8192
      # Gemini 2.5 Flash Lite - Ultra-fast responses
      - name: gemini/gemini-2.5-flash-lite
        category: small
        supports_system_role: false
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 1048576
        max_output_tokens: 65536
        default_max_tokens: 8192
      - name: gemini/gemini-flash-lite-latest
        category: small
        supports_system_role: false
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 1048576
        max_output_tokens: 65536
        default_max_tokens: 8192
      # Gemini 2.0 Flash - Previous generation flagship
      - name: gemini/gemini-2.0-flash
        category: medium
        supports_system_role: false
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 1048576
        max_output_tokens: 8192
        default_max_tokens: 8192
      - name: gemini/gemini-2.0-flash-001
        category: medium
        supports_system_role: false
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 1048576
        max_output_tokens: 8192
        default_max_tokens: 8192
      # Gemini 2.0 Flash Lite - Fast and lightweight
      - name: gemini/gemini-2.0-flash-lite
        category: small
        supports_system_role: false
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 1048576
        max_output_tokens: 8192
        default_max_tokens: 8192
      # Gemini 2.0 Pro Experimental - Advanced capabilities
      - name: gemini/gemini-2.0-pro-exp
        category: large
        supports_system_role: false
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 1048576
        max_output_tokens: 65536
        default_max_tokens: 8192
      # Gemini 2.0 Flash Thinking - Reasoning-focused
      - name: gemini/gemini-2.0-flash-thinking-exp
        category: medium
        supports_system_role: false
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 1048576
        max_output_tokens: 65536
        default_max_tokens: 8192
      # Gemini Experimental Models
      - name: gemini/gemini-exp-1206
        category: large
        supports_system_role: false
        max_temperature: 2
        temperature: 0.75
        max_input_tokens: 1048576
        max_output_tokens: 65536
        default_max_tokens: 8192
    default_model: gemini/gemini-2.5-flash

default: anthropic
# These are the preset creativity temperature settings for the engine and model.
temperature_settings:
  precise: 0.25
  balanced: 0.50
  creative: 0.75
